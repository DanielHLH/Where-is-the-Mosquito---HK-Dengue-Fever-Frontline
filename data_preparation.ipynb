{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This script contains the data preparation of Hong Kong monthly Ovitrap Index in different locations. The data is from Food and Environmental Hygiene Department(FEHD). The data from 2008 to 2017 is downloaded from FEHD in pdf format while the data from 2018 to now (July, 2018) is scrapped from the FEHD website. The processed data is converted to a csv file at the end of this script and it will be stored into a relational database in the next step."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import requests\n",
    "import re\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "def matched(patterns,values): #find out expressions that matched with the patterns\n",
    "    found = []\n",
    "    for pattern in patterns:\n",
    "        for value in values:\n",
    "            match = re.search(pattern,value)\n",
    "            if match:\n",
    "                found.append(value)\n",
    "    return set(found)\n",
    "\n",
    "def replace_value(to_replace,replace,df_column): #replace value in the dataframe column\n",
    "    for index,value in enumerate(to_replace): \n",
    "        df_column = df_column.replace(value,replace[index])\n",
    "    return df_column\n",
    "\n",
    "def make_row(row_list): \n",
    "    months = ['{:02d}'.format(i) for i in range(1,13)]\n",
    "    row_dict = {}\n",
    "    for index,value in enumerate(months):\n",
    "        row_dict[value] = { 'Eng': row_list[0],\n",
    "                            'Chi': row_list[1],\n",
    "                            'Date': \"{month}-{year}\".format(month=value,year=row_list[-1]),\n",
    "                            'AOI': row_list[index+2]\n",
    "                            }   \n",
    "    return row_dict\n",
    "\n",
    "def convert_float(number):\n",
    "    if '/' in number:\n",
    "        decimal = float(number[0:-2])/100\n",
    "        return round(decimal,3)\n",
    "    elif number[-1] == '%':\n",
    "        decimal = float(number[0:-1])/100\n",
    "        return round(decimal,3)\n",
    "    else:\n",
    "        decimal = float(number)/100\n",
    "        return round(decimal,3)    \n",
    "\n",
    "def classification(value):\n",
    "    if value < 0.05:\n",
    "        return 1\n",
    "    elif value >= 0.05 and value < 0.2:\n",
    "        return 2\n",
    "    elif value >= 0.2 and value < 0.4:\n",
    "        return 3\n",
    "    elif value >= 0.4:\n",
    "        return 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "archive = pd.read_csv(\"monthlyOvitrap_2008-2017.csv\",header=None)\n",
    "\n",
    "#use the table header at the fourth row as the header of the dataframe\n",
    "#only need the English parts\n",
    "new_col = {}\n",
    "for i in range(13):\n",
    "    splited = archive.loc[4,i].split('\\n')\n",
    "    new_col[i] = splited[0]\n",
    "\n",
    "archive.rename(columns=new_col,inplace=True)\n",
    "\n",
    "#find and drop all the rows that contain unwanted data\n",
    "patterns = [\"Food and Environmental Hygiene Department\",\"食物環境衛生署\",\"^Monthly\",\n",
    "            \"二零..年每月誘蚊產卵器分區指數\",\"Locations\\n地區\"]\n",
    "\n",
    "unwanted = matched(patterns,archive[\"Locations\"])\n",
    "for value in unwanted:\n",
    "    drop_index = archive[archive[\"Locations\"] == value].index\n",
    "    archive.drop(drop_index,inplace=True)\n",
    "\n",
    "archive.reset_index(drop=True,inplace=True)    \n",
    "\n",
    "#consistency is provided for inconsistent names of locations \n",
    "to_replace_1 = ['Central, Sheung Wan and Sai Ying\\nPun\\n中環, 上環及西營盤','Tseung Kwan O\\n將軍澳',\n",
    "                'Tseung Kwan O South (Formerly: Tseung Kwan O)\\n將軍澳南 (前稱: 將軍澳)',\n",
    "                'Tsing Yi\\n青衣','Tsing Yi South (Formerly: Tsing Yi)\\n青衣南 (前稱: 青衣)']\n",
    "\n",
    "replace_1 = ['Central, Sheung Wan and Sai Ying Pun\\n中環, 上環及西營盤','Tseung Kwan O South\\n將軍澳南',\n",
    "             'Tseung Kwan O South\\n將軍澳南','Tsing Yi South\\n青衣南','Tsing Yi South\\n青衣南']\n",
    "\n",
    "archive['Locations'] = replace_value(to_replace_1,replace_1,archive['Locations'])\n",
    "\n",
    "#Columns 'Eng' and 'Chi' are created to store the bilingual location \n",
    "for index, value in enumerate(archive['Locations']):\n",
    "    splited = value.split('\\n')\n",
    "    archive.loc[index,'Eng'] = splited[0]\n",
    "    archive.loc[index,'Chi'] = splited[1]\n",
    "\n",
    "archive.drop('Locations',axis=1,inplace=True)\n",
    "cols = archive.columns.tolist()\n",
    "cols = cols[-2:]+cols[:-2]\n",
    "archive = archive[cols]\n",
    "\n",
    "#Column 'Year' is created to stored the corresponding year\n",
    "archive.loc[:,'Year'] = pd.Series('NaN'for each in range(archive.shape[0]))\n",
    "year_interval = archive[archive['Eng'] == 'Chai Wan West'].index.tolist()\n",
    "for index, value in enumerate(range(2008,2018)):\n",
    "    try:\n",
    "        archive['Year'].loc[year_interval[index]:year_interval[index+1]] = value\n",
    "    except IndexError:\n",
    "        archive['Year'].loc[year_interval[index]:] = value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "response = requests.get(\"https://www.fehd.gov.hk/tc_chi/pestcontrol/dengue_fever/ovitrap_index.html\")\n",
    "content = response.content\n",
    "parser =  BeautifulSoup(content,'html.parser')\n",
    "\n",
    "scrapped = []\n",
    "for each in parser.select(\"td\"):\n",
    "    scrapped.append(each.text)\n",
    "    \n",
    "scrapped = scrapped[10:] # The first ten data are unrelated\n",
    "pattern = ['區$','月$'] # Data that match with anyone of these two Chinese words is not needed\n",
    "unwanted = matched(pattern,scrapped)\n",
    "\n",
    "wanted = []\n",
    "for value in scrapped:\n",
    "    if value not in unwanted:\n",
    "        wanted.append(value)\n",
    "\n",
    "interval = np.arange(0,len(wanted),13) # Every row is consisted of 13 data\n",
    "current = []\n",
    "for index,value in enumerate(interval):\n",
    "    location = wanted[value]\n",
    "    if location == \"香港國際機場\": # Port area are not the targets in this analysis\n",
    "        break\n",
    "    else:\n",
    "        current.append(wanted[value:interval[index+1]])\n",
    "\n",
    "for each in current: \n",
    "    each.insert(0,'') # Prepare a place for the 'Eng' column \n",
    "    each.append(2018) # Provide value for the 'Year' column\n",
    "    \n",
    "\n",
    "header = archive.columns.tolist() # set the same header for combination of datasets\n",
    "current = pd.DataFrame(current,columns=header)\n",
    "current.replace('',np.nan,inplace=True)     "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "combined = pd.concat([archive,current],axis=0,ignore_index=True)\n",
    "\n",
    "to_replace_2 = ['中環, 上環及西營盤','上環及西營盤(前稱: 中環,上環及西營盤)','將軍澳南(前稱: 將軍澳)','青衣南(前稱: 青衣)']\n",
    "replace_2 = ['上環及西營盤','上環及西營盤','將軍澳南','青衣南']\n",
    "combined['Chi'] = replace_value(to_replace_2,replace_2,combined['Chi'])\n",
    "\n",
    "to_replace_3 = ['Central, Sheung Wan and Sai Ying Pun','Tuen Mun (S)','Tuen Mun (N)']\n",
    "replace_3 = ['Sheung Wan and Sai Ying Pun','Tuen Mun South','Tuen Mun North'] \n",
    "combined['Eng'] = replace_value(to_replace_3,replace_3,combined['Eng'])\n",
    "\n",
    "eng_name = combined['Eng'].unique()\n",
    "chi_name = combined['Chi'].unique()\n",
    "eng_name = [name for name in eng_name if name is not np.nan]\n",
    "translations = list(zip(eng_name,chi_name))\n",
    "\n",
    "new_locations = [('Central and Admiralty','中環及金鐘'),('Yau Tong','油塘'),('Wo Che','禾輋'),\n",
    "                 ('Tuen Mun West','屯門西'),('Tsuen Wan West','荃灣西')]\n",
    "translations = translations + new_locations\n",
    "\n",
    "name_2018 = combined[combined['Year']==2018].loc[:,['Eng','Chi']]\n",
    "for translation in translations:\n",
    "    for index in name_2018.index:\n",
    "        if name_2018.loc[index][1] == translation[1]:\n",
    "            name_2018.loc[index][0] = translation[0]  \n",
    "combined.loc[name_2018.index,'Eng'] = name_2018['Eng']         "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "complete = pd.DataFrame(columns=['Eng','Chi','Date','AOI'])\n",
    "\n",
    "for i in combined.index:\n",
    "    row_list = combined.loc[i].tolist()\n",
    "    row_dict = make_row(row_list)\n",
    "    for key, value in row_dict.items():\n",
    "        complete = complete.append(value,ignore_index=True)\n",
    "\n",
    "complete.dropna(inplace=True)\n",
    "complete.reset_index(drop=True,inplace=True)\n",
    "complete['AOI'] = complete['AOI'].apply(convert_float)\n",
    "complete['Classification'] = complete['AOI'].apply(classification)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "complete.to_csv('Area_OviTrap_Index_Jan2008-Jul2018.csv',index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
